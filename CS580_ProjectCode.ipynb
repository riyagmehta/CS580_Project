{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2feab12a-0ddc-41f0-a987-7cbc49c3f4ee",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c093740b-769f-42a8-9019-73e09217b7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 8, 100),\n",
       " (6, 19, 102),\n",
       " (6, 19, 105),\n",
       " (8, 8, 100),\n",
       " (9, 20, 108),\n",
       " (9, 20, 109),\n",
       " (10, 19, 102),\n",
       " (10, 19, 105)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hash_join_problem1(R1, R2):\n",
    "    # Build a hash table on R2 using attribute B as the key.\n",
    "    # For each value of B, we store all full tuples from R2 that have that B.\n",
    "    h = {}\n",
    "    for t in R2:                \n",
    "        b = t[0]\n",
    "        if b not in h:\n",
    "            h[b] = []\n",
    "        h[b].append(t)         \n",
    "\n",
    "    # Now we scan R1 and look up matches in the hash table.\n",
    "    result = []\n",
    "    for (a, b) in R1:\n",
    "        if b in h:\n",
    "            # For each matching R2 tuple, produce the joined (A, B, C)\n",
    "            for (_, c) in h[b]:\n",
    "                result.append((a, b, c))\n",
    "    return result\n",
    "\n",
    "\n",
    "# Example dataset: 10 tuples in R1 and 10 in R2 \n",
    "R1 = [(1,12),(2,5),(3,10),(4,17),(5,8),(6,19),(7,16),(8,8),(9,20),(10,19)]\n",
    "R2 = [(8,100),(7,101),(19,102),(3,103),(1,104),(19,105),(11,106),(11,107),(20,108),(20,109)]\n",
    "\n",
    "# Run the join\n",
    "output = hash_join_problem1(R1, R2)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba77caf1-025b-4dda-94b9-e32acb59103d",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe388a7-138e-4f87-a242-4385d56b108b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 10, 100), (2, 3, 11, 101), (3, 4, 12, 102), (4, 5, 13, 103)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q(A1, A2, ..., Ak+1) :- R1(A1,A2), R2(A2,A3), ..., Rk(Ak, Ak+1)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def semijoin_reduce(left, right, join_attr_left, join_attr_right):\n",
    "   \n",
    "    right_keys = {t[join_attr_right] for t in right}\n",
    "    return [t for t in left if t[join_attr_left] in right_keys]\n",
    "\n",
    "\n",
    "def yannakakis_line_join(relations):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        relations = [R1, R2, ..., Rk]\n",
    "        where Ri is a list of tuples (Ai, Ai+1)\n",
    "\n",
    "    Output:\n",
    "        The full join result of the k-line path.\n",
    "    \"\"\"\n",
    "\n",
    "    k = len(relations)\n",
    "\n",
    "   \n",
    "    # 1. Bottom-up pass (semijoins)\n",
    "    \n",
    "    # Start from Rk and move backwards to R1\n",
    "    reduced = relations.copy()\n",
    "\n",
    "    for i in range(k - 1, 0, -1):\n",
    "        # Join attribute:\n",
    "        # Ri joins with Ri+1 on Ai+1\n",
    "        reduced[i-1] = semijoin_reduce(\n",
    "            left=reduced[i-1],\n",
    "            right=reduced[i],\n",
    "            join_attr_left=1,   # Ai+1 in Ri\n",
    "            join_attr_right=0   # Ai+1 in Ri+1\n",
    "        )\n",
    "\n",
    "   \n",
    "    # 2. Top-down pass (semijoins)\n",
    "   \n",
    "    for i in range(k - 1):\n",
    "        reduced[i+1] = semijoin_reduce(\n",
    "            left=reduced[i+1],\n",
    "            right=reduced[i],\n",
    "            join_attr_left=0,   # Ai+1 in Ri+1\n",
    "            join_attr_right=1   # Ai+1 in Ri\n",
    "        )\n",
    "\n",
    "    \n",
    "    # 3. Final join (now all small)\n",
    "    \n",
    "    # Start building the result from R1\n",
    "    result = [(a1, a2) for (a1, a2) in reduced[0]]  # (A1,A2)\n",
    "\n",
    "    # Extend step-by-step through remaining relations\n",
    "    for i in range(1, k):\n",
    "        next_rel = reduced[i]\n",
    "        \n",
    "        # Build an index for fast lookups\n",
    "        index = defaultdict(list)\n",
    "        for (x, y) in next_rel:\n",
    "            index[x].append(y)\n",
    "\n",
    "        new_result = []\n",
    "        for tup in result:\n",
    "            last_val = tup[-1]  # the Ai+1 value\n",
    "            if last_val in index:\n",
    "                for nxt in index[last_val]:\n",
    "                    new_result.append(tup + (nxt,))\n",
    "        result = new_result\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# Example: 3-line join (R1, R2, R3)\n",
    "\n",
    "R1 = [(1,2), (2,3), (3,4), (4,5)]\n",
    "R2 = [(2,10), (3,11), (4,12), (5,13)]\n",
    "R3 = [(10,100), (11,101), (12,102), (13,103)]\n",
    "\n",
    "relations = [R1, R2, R3]\n",
    "\n",
    "output = yannakakis_line_join(relations)\n",
    "output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880b5f1b-1ee7-4cda-afa9-70ca636bfd0d",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "670ca65e-29c9-4854-95a1-edc4607c110d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 10, 100), (2, 3, 11, 101), (3, 4, 12, 102), (4, 5, 13, 103)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q(A1, ..., Ak+1) :- R1(A1,A2), R2(A2,A3), ..., Rk(Ak,Ak+1)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# We reuse the hash join idea from Problem 1.\n",
    "def hash_join_two(rel_left, rel_right):\n",
    "    \"\"\"\n",
    "    Join two binary relations:\n",
    "    rel_left:  list of tuples (..., x)\n",
    "    rel_right: list of tuples (x, y)\n",
    "    Output: joined tuples (..., x, y)\n",
    "    \"\"\"\n",
    "    # Build a hash table on the first attribute of rel_right.\n",
    "    h = defaultdict(list)\n",
    "    for (x, y) in rel_right:\n",
    "        h[x].append(y)\n",
    "\n",
    "    result = []\n",
    "    for t in rel_left:\n",
    "        x = t[-1]  # the last attribute is the join key\n",
    "        if x in h:\n",
    "            for y in h[x]:\n",
    "                result.append(t + (y,))\n",
    "    return result\n",
    "\n",
    "\n",
    "def naive_line_join(relations):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        relations = [R1, R2, ..., Rk]\n",
    "        where Ri is a list of tuples (Ai, Ai+1)\n",
    "\n",
    "    Output:\n",
    "        All joined tuples from R1 ⋈ R2 ⋈ ... ⋈ Rk\n",
    "    \"\"\"\n",
    "\n",
    "    # Start by converting R1(A1,A2) into tuples (A1,A2)\n",
    "    result = [(a1, a2) for (a1, a2) in relations[0]]\n",
    "\n",
    "    # Iteratively join with R2, R3, ..., Rk\n",
    "    for i in range(1, len(relations)):\n",
    "        result = hash_join_two(result, relations[i])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# Example dataset for a 3-line join\n",
    "\n",
    "R1 = [(1,2), (2,3), (3,4), (4,5)]\n",
    "R2 = [(2,10), (3,11), (4,12), (5,13)]\n",
    "R3 = [(10,100), (11,101), (12,102), (13,103)]\n",
    "\n",
    "relations = [R1, R2, R3]\n",
    "\n",
    "output_problem3 = naive_line_join(relations)\n",
    "output_problem3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1c72fa-a2e3-4b95-a87f-9784977f3c14",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4741e12-6c39-4206-bffb-d5d122ea5b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0003056996501982212, 0.00037400005385279655, True, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# Create the 3 relations \n",
    "# R1: (i, x) for i=1..100, x random in [1,5000]\n",
    "R1_100 = [(i, random.randint(1, 5000)) for i in range(1, 101)]\n",
    "\n",
    "# R2: (y, j) for j=1..100, y random in [1,5000]\n",
    "R2_100 = [(random.randint(1, 5000), j) for j in range(1, 101)]\n",
    "\n",
    "# R3: (ℓ, ℓ) for ℓ=1..100\n",
    "R3_100 = [(l, l) for l in range(1, 101)]\n",
    "\n",
    "relations_3line = [R1_100, R2_100, R3_100]\n",
    "\n",
    "\n",
    "#Run Problem 2\n",
    "start_p2 = time.perf_counter()\n",
    "output_p2 = yannakakis_line_join(relations_3line)\n",
    "time_p2 = time.perf_counter() - start_p2\n",
    "\n",
    "#Run Problem 3\n",
    "start_p3 = time.perf_counter()\n",
    "output_p3 = naive_line_join(relations_3line)\n",
    "time_p3 = time.perf_counter() - start_p3\n",
    "\n",
    "\n",
    "same_output = set(output_p2) == set(output_p3)\n",
    "len_output = len(output_p2)\n",
    "\n",
    "# Return timing + correctness check + output size\n",
    "time_p2, time_p3, same_output, len_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626e7a1a",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d98721e-52a8-4608-946b-188a2550bb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 1001, 0.004727200139313936, 0.8710366999730468)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import random, time\n",
    "\n",
    "# Construct R1\n",
    "R1_p5 = []\n",
    "R1_p5 += [(i,5) for i in range(1,1001)]\n",
    "R1_p5 += [(i,7) for i in range(1001,2001)]\n",
    "R1_p5.append((2001,2002))\n",
    "random.shuffle(R1_p5)\n",
    "\n",
    "# Construct R2\n",
    "R2_p5 = []\n",
    "R2_p5 += [(5,i) for i in range(1,1001)]\n",
    "R2_p5 += [(7,i) for i in range(1001,2001)]\n",
    "R2_p5.append((2002,8))\n",
    "random.shuffle(R2_p5)\n",
    "\n",
    "# Construct R3\n",
    "R3_p5 = [(random.randint(2002,3000), random.randint(1,3000)) for _ in range(2000)]\n",
    "R3_p5.append((8,30))\n",
    "random.shuffle(R3_p5)\n",
    "\n",
    "relations_p5 = [R1_p5, R2_p5, R3_p5]\n",
    "\n",
    "# Run Problem 2\n",
    "t0 = time.perf_counter()\n",
    "out_p2 = yannakakis_line_join(relations_p5)\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "# Run Problem 3\n",
    "t2 = time.perf_counter()\n",
    "out_p3 = naive_line_join(relations_p5)\n",
    "t3 = time.perf_counter()\n",
    "\n",
    "(len(out_p2), len(out_p3), t1-t0, t3-t2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecc4561",
   "metadata": {},
   "source": [
    "# Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f588e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "R1 = pd.read_csv(r\"QueryRelations\\R1.csv\", skiprows=1, header=None, names=[\"A1\",\"A2\"])\n",
    "R2 = pd.read_csv(r\"QueryRelations\\R2.csv\", skiprows=1, header=None, names=[\"A2\",\"A3\"])\n",
    "R3 = pd.read_csv(r\"QueryRelations\\R3.csv\", skiprows=1, header=None, names=[\"A1\",\"A3\"])\n",
    "R4 = pd.read_csv(r\"QueryRelations\\R4.csv\", skiprows=1, header=None, names=[\"A3\",\"A4\"])\n",
    "R5 = pd.read_csv(r\"QueryRelations\\R5.csv\", skiprows=1, header=None, names=[\"A4\",\"A5\"])\n",
    "R6 = pd.read_csv(r\"QueryRelations\\R6.csv\", skiprows=1, header=None, names=[\"A5\",\"A6\"])\n",
    "R7 = pd.read_csv(r\"QueryRelations\\R7.csv\", skiprows=1, header=None, names=[\"A4\",\"A6\"])\n",
    "\n",
    "#R1.head(), R2.head(), R3.head(), R4.head(), R5.head(), R6.head(), R7.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb9f5ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_join_query(R1,R2,R3,R4,R5,R6,R7):\n",
    "    R1t = [tuple(x) for x in R1.to_numpy()]\n",
    "    R2t = [tuple(x) for x in R2.to_numpy()]\n",
    "    R3t = [tuple(x) for x in R3.to_numpy()]\n",
    "    R4t = [tuple(x) for x in R4.to_numpy()]\n",
    "    R5t = [tuple(x) for x in R5.to_numpy()]\n",
    "    R6t = [tuple(x) for x in R6.to_numpy()]\n",
    "    R7t = [tuple(x) for x in R7.to_numpy()]\n",
    "\n",
    "    out = []\n",
    "\n",
    "    for (a1,a2) in R1t:\n",
    "        for (a2b,a3) in R2t:\n",
    "            if a2 != a2b: continue\n",
    "            for (a1b,a3b) in R3t:\n",
    "                if a1 != a1b or a3 != a3b: continue\n",
    "                for (a3c,a4) in R4t:\n",
    "                    if a3 != a3c: continue\n",
    "                    for (a4b,a5) in R5t:\n",
    "                        if a4 != a4b: continue\n",
    "                        for (a5b,a6) in R6t:\n",
    "                            if a5 != a5b: continue\n",
    "                            for (a4c,a6b) in R7t:\n",
    "                                if a4 == a4c and a6 == a6b:\n",
    "                                    out.append((a1,a2,a3,a4,a5,a6))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65acbdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ghw_join(R1,R2,R3,R4,R5,R6,R7):\n",
    "\n",
    "    J1 = R1.merge(R2, on=\"A2\", how=\"inner\")\n",
    "    J2 = J1.merge(R3, on=[\"A1\",\"A3\"], how=\"inner\")\n",
    "    J3 = J2.merge(R4, on=\"A3\", how=\"inner\")\n",
    "    J4 = J3.merge(R5, on=\"A4\", how=\"inner\")\n",
    "    J5 = J4.merge(R6, on=\"A5\", how=\"inner\")\n",
    "    J6 = J5.merge(R7, on=[\"A4\",\"A6\"], how=\"inner\")\n",
    "\n",
    "    return J6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9563edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fhw_join(R1,R2,R3,R4,R5,R6,R7):\n",
    "    return ghw_join(R1,R2,R3,R4,R5,R6,R7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d709eff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1    int32\n",
       "A2    int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix for dtype mismatch across A1..A6 to avoid merge errors\n",
    "cols = [\"A1\",\"A2\",\"A3\",\"A4\",\"A5\",\"A6\"]\n",
    "\n",
    "def normalize_df(df):\n",
    "    for c in df.columns:\n",
    "        df[c] = df[c].astype(str).astype(int)\n",
    "    return df\n",
    "\n",
    "R1 = normalize_df(R1)\n",
    "R2 = normalize_df(R2)\n",
    "R3 = normalize_df(R3)\n",
    "R4 = normalize_df(R4)\n",
    "R5 = normalize_df(R5)\n",
    "R6 = normalize_df(R6)\n",
    "R7 = normalize_df(R7)\n",
    "\n",
    "R1.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7586cd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.63165729958564,\n",
       " 0.3786563999019563,\n",
       " 0.36425350001081824,\n",
       " 1000000,\n",
       " 1000000,\n",
       " 1000000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Generic Join\n",
    "t0 = time.perf_counter()\n",
    "gj_out = generic_join_query(R1,R2,R3,R4,R5,R6,R7)\n",
    "t1 = time.perf_counter()\n",
    "generic_time = t1 - t0\n",
    "\n",
    "# GHW Join\n",
    "t0 = time.perf_counter()\n",
    "ghw_out = ghw_join(R1,R2,R3,R4,R5,R6,R7)\n",
    "t1 = time.perf_counter()\n",
    "ghw_time = t1 - t0\n",
    "\n",
    "# FHW Join\n",
    "t0 = time.perf_counter()\n",
    "fhw_out = fhw_join(R1,R2,R3,R4,R5,R6,R7)\n",
    "t1 = time.perf_counter()\n",
    "fhw_time = t1 - t0\n",
    "\n",
    "generic_time, ghw_time, fhw_time, len(gj_out), len(ghw_out), len(fhw_out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
