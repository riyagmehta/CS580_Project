{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2feab12a-0ddc-41f0-a987-7cbc49c3f4ee",
   "metadata": {},
   "source": [
    "## Problem 1 — Hash Join Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c093740b-769f-42a8-9019-73e09217b7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of Hash Join (A, B, C tuples):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(5, 8, 100),\n",
       " (6, 19, 102),\n",
       " (6, 19, 105),\n",
       " (8, 8, 100),\n",
       " (9, 20, 108),\n",
       " (9, 20, 109),\n",
       " (10, 19, 102),\n",
       " (10, 19, 105)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hash_join_problem1(R1, R2):\n",
    "    # Build a hash table on R2 using attribute B as the key.\n",
    "    # For each value of B, we store all full tuples from R2 that have that B.\n",
    "    h = {}\n",
    "    for t in R2:                \n",
    "        b = t[0]\n",
    "        if b not in h:\n",
    "            h[b] = []\n",
    "        h[b].append(t)         \n",
    "\n",
    "    # Now we scan R1 and look up matches in the hash table.\n",
    "    result = []\n",
    "    for (a, b) in R1:\n",
    "        if b in h:\n",
    "            # For each matching R2 tuple, produce the joined (A, B, C)\n",
    "            for (_, c) in h[b]:\n",
    "                result.append((a, b, c))\n",
    "    return result\n",
    "\n",
    "# Example dataset: 10 tuples in R1 and 10 in R2 \n",
    "R1 = [(1,12),(2,5),(3,10),(4,17),(5,8),(6,19),(7,16),(8,8),(9,20),(10,19)]\n",
    "R2 = [(8,100),(7,101),(19,102),(3,103),(1,104),(19,105),(11,106),(11,107),(20,108),(20,109)]\n",
    "\n",
    "# Run the join\n",
    "print(\"Output of Hash Join (A, B, C tuples):\")\n",
    "output = hash_join_problem1(R1, R2)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba77caf1-025b-4dda-94b9-e32acb59103d",
   "metadata": {},
   "source": [
    "## Problem 2 — Yannakakis-Style Line Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe388a7-138e-4f87-a242-4385d56b108b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of Yannakakis Join (A1, A2, ..., Ak+1 tuples):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 2, 10, 100), (2, 3, 11, 101), (3, 4, 12, 102), (4, 5, 13, 103)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q(A1, A2, ..., Ak+1) :- R1(A1,A2), R2(A2,A3), ..., Rk(Ak, Ak+1)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def semijoin_reduce(left, right, join_attr_left, join_attr_right):\n",
    "   \n",
    "    right_keys = {t[join_attr_right] for t in right}\n",
    "    return [t for t in left if t[join_attr_left] in right_keys]\n",
    "\n",
    "def yannakakis_line_join(relations):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        relations = [R1, R2, ..., Rk]\n",
    "        where Ri is a list of tuples (Ai, Ai+1)\n",
    "\n",
    "    Output:\n",
    "        The full join result of the k-line path.\n",
    "    \"\"\"\n",
    "    k = len(relations)\n",
    "\n",
    "    # 1. Bottom-up pass (semijoins)\n",
    "\n",
    "    # Start from Rk and move backwards to R1\n",
    "    reduced = relations.copy()\n",
    "\n",
    "    for i in range(k - 1, 0, -1):\n",
    "        # Join attribute:\n",
    "        # Ri joins with Ri+1 on Ai+1\n",
    "        reduced[i-1] = semijoin_reduce(\n",
    "            left=reduced[i-1],\n",
    "            right=reduced[i],\n",
    "            join_attr_left=1,   # Ai+1 in Ri\n",
    "            join_attr_right=0   # Ai+1 in Ri+1\n",
    "        )\n",
    "   \n",
    "    # 2. Top-down pass (semijoins)\n",
    "   \n",
    "    for i in range(k - 1):\n",
    "        reduced[i+1] = semijoin_reduce(\n",
    "            left=reduced[i+1],\n",
    "            right=reduced[i],\n",
    "            join_attr_left=0,   # Ai+1 in Ri+1\n",
    "            join_attr_right=1   # Ai+1 in Ri\n",
    "        )\n",
    "\n",
    "    # 3. Final join (now all small)\n",
    "    \n",
    "    # Start building the result from R1\n",
    "    result = [(a1, a2) for (a1, a2) in reduced[0]]  # (A1,A2)\n",
    "\n",
    "    # Extend step-by-step through remaining relations\n",
    "    for i in range(1, k):\n",
    "        next_rel = reduced[i]\n",
    "        \n",
    "        # Build an index for fast lookups\n",
    "        index = defaultdict(list)\n",
    "        for (x, y) in next_rel:\n",
    "            index[x].append(y)\n",
    "\n",
    "        new_result = []\n",
    "        for tup in result:\n",
    "            last_val = tup[-1]  # the Ai+1 value\n",
    "            if last_val in index:\n",
    "                for nxt in index[last_val]:\n",
    "                    new_result.append(tup + (nxt,))\n",
    "        result = new_result\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example: 3-line join (R1, R2, R3)\n",
    "\n",
    "R1 = [(1,2), (2,3), (3,4), (4,5)]\n",
    "R2 = [(2,10), (3,11), (4,12), (5,13)]\n",
    "R3 = [(10,100), (11,101), (12,102), (13,103)]\n",
    "\n",
    "relations = [R1, R2, R3]\n",
    "\n",
    "print(\"Output of Yannakakis Join (A1, A2, ..., Ak+1 tuples):\")\n",
    "output = yannakakis_line_join(relations)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880b5f1b-1ee7-4cda-afa9-70ca636bfd0d",
   "metadata": {},
   "source": [
    "## Problem 3 — Naive Cascading Line Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "670ca65e-29c9-4854-95a1-edc4607c110d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output — Naive Line Join (A1, A2, ..., Ak+1 tuples):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 2, 10, 100), (2, 3, 11, 101), (3, 4, 12, 102), (4, 5, 13, 103)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q(A1, ..., Ak+1) :- R1(A1,A2), R2(A2,A3), ..., Rk(Ak,Ak+1)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# We reuse the hash join idea from Problem 1.\n",
    "def hash_join_two(rel_left, rel_right):\n",
    "    \"\"\"\n",
    "    Join two binary relations:\n",
    "    rel_left:  list of tuples (..., x)\n",
    "    rel_right: list of tuples (x, y)\n",
    "    Output: joined tuples (..., x, y)\n",
    "    \"\"\"\n",
    "    # Build a hash table on the first attribute of rel_right.\n",
    "    h = defaultdict(list)\n",
    "    for (x, y) in rel_right:\n",
    "        h[x].append(y)\n",
    "\n",
    "    result = []\n",
    "    for t in rel_left:\n",
    "        x = t[-1]  # the last attribute is the join key\n",
    "        if x in h:\n",
    "            for y in h[x]:\n",
    "                result.append(t + (y,))\n",
    "    return result\n",
    "\n",
    "def naive_line_join(relations):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        relations = [R1, R2, ..., Rk]\n",
    "        where Ri is a list of tuples (Ai, Ai+1)\n",
    "\n",
    "    Output:\n",
    "        All joined tuples from R1 ⋈ R2 ⋈ ... ⋈ Rk\n",
    "    \"\"\"\n",
    "    # Start by converting R1(A1,A2) into tuples (A1,A2)\n",
    "    result = [(a1, a2) for (a1, a2) in relations[0]]\n",
    "\n",
    "    # Iteratively join with R2, R3, ..., Rk\n",
    "    for i in range(1, len(relations)):\n",
    "        result = hash_join_two(result, relations[i])\n",
    "    return result\n",
    "\n",
    "# Example dataset for a 3-line join\n",
    "\n",
    "R1 = [(1,2), (2,3), (3,4), (4,5)]\n",
    "R2 = [(2,10), (3,11), (4,12), (5,13)]\n",
    "R3 = [(10,100), (11,101), (12,102), (13,103)]\n",
    "\n",
    "relations = [R1, R2, R3]\n",
    "\n",
    "print(\"Output — Naive Line Join (A1, A2, ..., Ak+1 tuples):\")\n",
    "output_problem3 = naive_line_join(relations)\n",
    "output_problem3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1c72fa-a2e3-4b95-a87f-9784977f3c14",
   "metadata": {},
   "source": [
    "## Problem 4 — Random Dataset for 3-Line Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4741e12-6c39-4206-bffb-d5d122ea5b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yannakakis Time:  0.000372900627553463\n",
      "Naive Time:   0.00045559927821159363\n",
      "Same Output?  True\n",
      "Output Size:  4\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# Create the 3 relations \n",
    "# R1: (i, x) for i=1..100, x random in [1,5000]\n",
    "R1_100 = [(i, random.randint(1, 5000)) for i in range(1, 101)]\n",
    "\n",
    "# R2: (y, j) for j=1..100, y random in [1,5000]\n",
    "R2_100 = [(random.randint(1, 5000), j) for j in range(1, 101)]\n",
    "\n",
    "# R3: (ℓ, ℓ) for ℓ=1..100\n",
    "R3_100 = [(l, l) for l in range(1, 101)]\n",
    "\n",
    "relations_3line = [R1_100, R2_100, R3_100]\n",
    "\n",
    "#Run Problem 2\n",
    "start_p2 = time.perf_counter()\n",
    "output_p2 = yannakakis_line_join(relations_3line)\n",
    "time_p2 = time.perf_counter() - start_p2\n",
    "\n",
    "#Run Problem 3\n",
    "start_p3 = time.perf_counter()\n",
    "output_p3 = naive_line_join(relations_3line)\n",
    "time_p3 = time.perf_counter() - start_p3\n",
    "\n",
    "same_output = set(output_p2) == set(output_p3)\n",
    "len_output = len(output_p2)\n",
    "\n",
    "print(\"Yannakakis Time: \",time_p2)\n",
    "print(\"Naive Time:  \", time_p3)\n",
    "print(\"Same Output? \",same_output)\n",
    "print(\"Output Size: \",len_output )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626e7a1a",
   "metadata": {},
   "source": [
    "## Problem 5 — Large Structured Dataset for 3-Line Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d98721e-52a8-4608-946b-188a2550bb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Problem 5 datasets in folder: DatasetforThreelineQuery/\n",
      "Files created: R1_p5.csv, R2_p5.csv, R3_p5.csv\n",
      "Output size (Problem 2): 1001\n",
      "Output size (Problem 3): 1001\n",
      "Same outputs?: True\n",
      "Problem 2 runtime: 0.002710900269448757\n",
      "Problem 3 runtime: 0.9798926999792457\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# PROBLEM 5 — Dataset Construction \n",
    "\n",
    "# Construct R1\n",
    "R1_p5 = []\n",
    "R1_p5 += [(i, 5) for i in range(1, 1001)]\n",
    "R1_p5 += [(i, 7) for i in range(1001, 2001)]\n",
    "R1_p5.append((2001, 2002))\n",
    "random.shuffle(R1_p5)\n",
    "\n",
    "# Construct R2\n",
    "R2_p5 = []\n",
    "R2_p5 += [(5, i) for i in range(1, 1001)]\n",
    "R2_p5 += [(7, i) for i in range(1001, 2001)]\n",
    "R2_p5.append((2002, 8))\n",
    "random.shuffle(R2_p5)\n",
    "\n",
    "# Construct R3\n",
    "R3_p5 = [(random.randint(2002,3000), random.randint(1,3000)) for _ in range(2000)]\n",
    "R3_p5.append((8, 30))\n",
    "random.shuffle(R3_p5)\n",
    "\n",
    "relations_p5 = [R1_p5, R2_p5, R3_p5]\n",
    "\n",
    "# Run Problem 2 implementation (Yannakakis line join)\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "out_p2 = yannakakis_line_join(relations_p5)\n",
    "t1 = time.perf_counter()\n",
    "time_p2 = t1 - t0\n",
    "\n",
    "# Run Problem 3 implementation (Naive hash-chain join)\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "out_p3 = naive_line_join(relations_p5)\n",
    "t3 = time.perf_counter()\n",
    "time_p3 = t3 - t2\n",
    "\n",
    "# CREATE FOLDER AND SAVE CSVs INSIDE IT\n",
    "\n",
    "folder = \"DatasetforThreeLineQuery\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "df_R1 = pd.DataFrame(R1_p5, columns=[\"A1\", \"A2\"])\n",
    "df_R2 = pd.DataFrame(R2_p5, columns=[\"A2\", \"A3\"])\n",
    "df_R3 = pd.DataFrame(R3_p5, columns=[\"A3\", \"A4\"])\n",
    "\n",
    "df_R1.to_csv(f\"{folder}/R1_p5.csv\", index=False)\n",
    "df_R2.to_csv(f\"{folder}/R2_p5.csv\", index=False)\n",
    "df_R3.to_csv(f\"{folder}/R3_p5.csv\", index=False)\n",
    "\n",
    "print(\"Saved Problem 5 datasets in folder: DatasetforThreelineQuery/\")\n",
    "print(\"Files created: R1_p5.csv, R2_p5.csv, R3_p5.csv\")\n",
    "\n",
    "# PRINT METRICS\n",
    "\n",
    "print(\"Output size (Problem 2):\", len(out_p2))\n",
    "print(\"Output size (Problem 3):\", len(out_p3))\n",
    "print(\"Same outputs?:\", set(out_p2) == set(out_p3))\n",
    "print(\"Problem 2 runtime:\", time_p2)\n",
    "print(\"Problem 3 runtime:\", time_p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63711d7e",
   "metadata": {},
   "source": [
    "## Problem 6 is in the SQL file outside this IPYNB File named Problem6.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecc4561",
   "metadata": {},
   "source": [
    "## Problem 7 — Generic Join, GHW, and FHW Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31bb8960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generic Join runtime:    9.875571 seconds\n",
      "GHW Join runtime:        0.457814 seconds\n",
      "FHW Join runtime:        0.381953 seconds\n",
      "\n",
      "Generic Join output size: 1000000\n",
      "GHW Join output size:     1000000\n",
      "FHW Join output size:     1000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# LOAD ALL SEVEN RELATIONS\n",
    "\n",
    "R1 = pd.read_csv(\"QueryRelations/R1.csv\")\n",
    "R2 = pd.read_csv(\"QueryRelations/R2.csv\")\n",
    "R3 = pd.read_csv(\"QueryRelations/R3.csv\")\n",
    "R4 = pd.read_csv(\"QueryRelations/R4.csv\")\n",
    "R5 = pd.read_csv(\"QueryRelations/R5.csv\")\n",
    "R6 = pd.read_csv(\"QueryRelations/R6.csv\")\n",
    "R7 = pd.read_csv(\"QueryRelations/R7.csv\")\n",
    "\n",
    "# GENERIC JOIN, GHW JOIN, FHW JOIN\n",
    "\n",
    "# ---- Helper: DF → list of tuples ----\n",
    "def df_to_tuples(df):\n",
    "    return [tuple(x) for x in df.to_numpy()]\n",
    "\n",
    "# ---- Helper: DF → list of dicts ----\n",
    "def to_dict_list(df):\n",
    "    return df.to_dict(\"records\")\n",
    "\n",
    "# ---- Make separate clean copies for Generic Join ----\n",
    "R1_copy = R1.copy()\n",
    "R2_copy = R2.copy()\n",
    "R3_copy = R3.copy()\n",
    "R4_copy = R4.copy()\n",
    "R5_copy = R5.copy()\n",
    "R6_copy = R6.copy()\n",
    "R7_copy = R7.copy()\n",
    "\n",
    "R1t = df_to_tuples(R1_copy)\n",
    "R2t = df_to_tuples(R2_copy)\n",
    "R3t = df_to_tuples(R3_copy)\n",
    "R4t = df_to_tuples(R4_copy)\n",
    "R5t = df_to_tuples(R5_copy)\n",
    "R6t = df_to_tuples(R6_copy)\n",
    "R7t = df_to_tuples(R7_copy)\n",
    "\n",
    "# ATTRIBUTE SCHEMAS\n",
    "\n",
    "A1 = [\"A1\",\"A2\"]\n",
    "A2 = [\"A2\",\"A3\"]\n",
    "A3 = [\"A1\",\"A3\"]\n",
    "A4 = [\"A3\",\"A4\"]\n",
    "A5 = [\"A4\",\"A5\"]\n",
    "A6 = [\"A5\",\"A6\"]\n",
    "A7 = [\"A4\",\"A6\"]\n",
    "\n",
    "# GENERIC JOIN (AGM)\n",
    "\n",
    "def project(R, idx):\n",
    "    return set(row[idx] for row in R)\n",
    "\n",
    "def filter_eq(R, idx, value):\n",
    "    return [row for row in R if row[idx] == value]\n",
    "\n",
    "def generic_join(relations, attributes):\n",
    "    if not attributes:\n",
    "        return [dict()]\n",
    "\n",
    "    X = attributes[0]\n",
    "\n",
    "    R_with_X = [(R, A.index(X), A) for (R,A) in relations if X in A]\n",
    "\n",
    "    domain = None\n",
    "    for (R, idx, A) in R_with_X:\n",
    "        vals = project(R, idx)\n",
    "        domain = vals if domain is None else domain & vals\n",
    "\n",
    "    outputs = []\n",
    "    for val in domain:\n",
    "        new_rel = []\n",
    "        for (R, A) in relations:\n",
    "            if X in A:\n",
    "                idx = A.index(X)\n",
    "                Rf = filter_eq(R, idx, val)\n",
    "                new_rel.append((Rf, A))\n",
    "            else:\n",
    "                new_rel.append((R, A))\n",
    "\n",
    "        subs = generic_join(new_rel, attributes[1:])\n",
    "        for s in subs:\n",
    "            s[X] = val\n",
    "            outputs.append(s)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "# GHW (YANNAKAKIS) JOIN\n",
    "\n",
    "def semijoin(parent, child, pkey, ckey):\n",
    "    S = set(t[pkey] for t in parent)\n",
    "    return [t for t in child if t[ckey] in S]\n",
    "\n",
    "def ghw_join(R1,R2,R3,R4,R5,R6,R7):\n",
    "\n",
    "    # convert to dicts\n",
    "    R1d = to_dict_list(R1)\n",
    "    R2d = to_dict_list(R2)\n",
    "    R3d = to_dict_list(R3)\n",
    "    R4d = to_dict_list(R4)\n",
    "    R5d = to_dict_list(R5)\n",
    "    R6d = to_dict_list(R6)\n",
    "    R7d = to_dict_list(R7)\n",
    "\n",
    "    # bottom-up semijoins\n",
    "    R6d = semijoin(R5d, R6d, \"A5\", \"A5\")\n",
    "    R7d = semijoin(R4d, R7d, \"A4\", \"A4\")\n",
    "    R5d = semijoin(R4d, R5d, \"A4\", \"A4\")\n",
    "    R4d = semijoin(R3d, R4d, \"A3\", \"A3\")\n",
    "    R3d = semijoin(R1d, R3d, \"A1\", \"A1\")\n",
    "    R2d = semijoin(R1d, R2d, \"A2\", \"A2\")\n",
    "\n",
    "    # top-down pruning\n",
    "    R1d = semijoin(R3d, semijoin(R2d, R1d, \"A2\", \"A2\"), \"A1\", \"A1\")\n",
    "\n",
    "    # final merge-join pipeline\n",
    "    out = (\n",
    "        pd.DataFrame(R1d)\n",
    "          .merge(pd.DataFrame(R2d), on=\"A2\")\n",
    "          .merge(pd.DataFrame(R3d), on=[\"A1\",\"A3\"])\n",
    "          .merge(pd.DataFrame(R4d), on=\"A3\")\n",
    "          .merge(pd.DataFrame(R5d), on=\"A4\")\n",
    "          .merge(pd.DataFrame(R6d), on=\"A5\")\n",
    "          .merge(pd.DataFrame(R7d), on=[\"A4\",\"A6\"])\n",
    "    )\n",
    "    return out\n",
    "\n",
    "# FHW JOIN = same as GHW for this query\n",
    "\n",
    "def fhw_join(R1,R2,R3,R4,R5,R6,R7):\n",
    "    return ghw_join(R1,R2,R3,R4,R5,R6,R7)\n",
    "\n",
    "# RUN ALL THREE ALGORITHMS\n",
    "\n",
    "full_attrs = [\"A1\",\"A2\",\"A3\",\"A4\",\"A5\",\"A6\"]\n",
    "\n",
    "relations_set = [\n",
    "    (R1t, A1), (R2t, A2), (R3t, A3),\n",
    "    (R4t, A4), (R5t, A5), (R6t, A6), (R7t, A7)\n",
    "]\n",
    "\n",
    "# --- GENERIC JOIN ---\n",
    "t0 = time.perf_counter()\n",
    "gj_out = generic_join(relations_set, full_attrs)\n",
    "generic_time = time.perf_counter() - t0\n",
    "generic_size = len(gj_out)\n",
    "\n",
    "# --- GHW ---\n",
    "t0 = time.perf_counter()\n",
    "ghw_out = ghw_join(R1.copy(), R2.copy(), R3.copy(),\n",
    "                   R4.copy(), R5.copy(), R6.copy(), R7.copy())\n",
    "ghw_time = time.perf_counter() - t0\n",
    "ghw_size = len(ghw_out)\n",
    "\n",
    "# --- FHW ---\n",
    "t0 = time.perf_counter()\n",
    "fhw_out = fhw_join(R1.copy(), R2.copy(), R3.copy(),\n",
    "                   R4.copy(), R5.copy(), R6.copy(), R7.copy())\n",
    "fhw_time = time.perf_counter() - t0\n",
    "fhw_size = len(fhw_out)\n",
    "\n",
    "print(f\"Generic Join runtime:    {generic_time:.6f} seconds\")\n",
    "print(f\"GHW Join runtime:        {ghw_time:.6f} seconds\")\n",
    "print(f\"FHW Join runtime:        {fhw_time:.6f} seconds\")\n",
    "print()\n",
    "print(f\"Generic Join output size: {generic_size}\")\n",
    "print(f\"GHW Join output size:     {ghw_size}\")\n",
    "print(f\"FHW Join output size:     {fhw_size}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
